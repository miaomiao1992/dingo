# Code Review: Phase 2.2 Error Propagation Implementation
**Reviewer:** x-ai/grok-code-fast-1
**Date:** 2025-11-17
**Session:** 20251117-183117

## Executive Summary

This is a comprehensive review of the Go implementation for the Dingo project's error propagation feature (Phase 2.2: Error Propagation Integration). The review analyzed three key files (`pkg/preprocessor/error_prop.go`, `pkg/preprocessor/type_annot.go`, and `pkg/preprocessor/keywords.go`) against correctness, Go best practices, performance, code quality, architecture, and edge cases.

**Overall Assessment:** The code has a solid foundation for error propagation but contains **2 CRITICAL bugs** that must be fixed before merging. These bugs will cause compile errors on common Go patterns. Several **IMPORTANT** issues should also be addressed for reliability.

## Issues by Category

### CRITICAL Issues

#### 1. Incorrect zero value generation for custom/struct types
**File:** `pkg/preprocessor/error_prop.go`
**Lines:** ~344-393 (`getZeroValue` function)
**Location:** Zero value fallback logic

**Issue:**
The `getZeroValue` helper correctly maps built-in types but falls back to `"nil"` for unknown/composite types. This will cause compilation errors if a function returns a struct or complex type, as `"nil"` is not assignable to non-nil types.

```go
// Current fallback (line ~392)
return "nil" // Safe fallback for unknown types

// Problem: For func foo() (MyStruct, error)
// Generates: return nil, err  ← COMPILE ERROR
```

**Impact:**
- Breaks code generation for functions returning custom types (e.g., `func foo() (MyStruct, error)`)
- The transpiled Go code won't compile, preventing end-to-end builds
- Violates the "Full Compatibility" design principle (interoperating with existing Go code)
- Will cause all golden tests with custom return types to fail

**Recommendation:**
Update `getZeroValue` to use `typ + "{}"` for fallback cases to generate proper composite literals:

```go
// Custom type → zero value using composite literal
// This works for most structs
if !strings.HasPrefix(typ, "*") && !strings.HasPrefix(typ, "[]") {
    // Qualified types (e.g., pkg.Type) need careful handling
    return typ + "{}"
}
return "nil" // Only for truly nil-able types
```

For a more robust solution, parse the type using `go/types` to infer the correct zero value. Add comprehensive tests against `tests/golden/result_*.dingo` files that include custom return types.

---

#### 2. Unreliable function signature parsing
**File:** `pkg/preprocessor/error_prop.go`
**Lines:** ~278-341 (`parseFunctionSignature` function)
**Location:** Function signature extraction and parsing

**Issue:**
Uses string concatenation to reconstruct a Go file (adding `"package p\n"` prefix and `}` suffix), then relies on `go/parser.ParseFile` to extract return types. This approach fails for:
- Functions with generics: `func foo[T any]() (T, error)`
- Interfaces in parameters: `func foo(x interface{ Stringer })`
- Multiline signatures spanning `{}`
- Complex nested expressions

The code uses `bytes.LastIndexByte(')')` which can pick the wrong closing parenthesis. Silent errors fall back to invalid zero values (`"nil"`).

```go
// Line ~290
src := fmt.Sprintf("package p\n%s}", funcText.String())
file, err := parser.ParseFile(fset, "", src, 0)
if err != nil {
    // Failed to parse, use nil fallback
    return &funcContext{
        returnTypes: []string{},
        zeroValues:  []string{"nil"},  ← SILENT FAILURE
    }
}
```

**Impact:**
- Silent failures lead to incorrect zero values/code generation
- Breaks error propagation for functions with generics (increasingly common in modern Go)
- Violates the "Zero Runtime Overhead" principle (generated code must compile cleanly)
- No error reporting to user when parsing fails

**Recommendation:**
1. **Short-term:** Add validation before parsing:
   - Parse incrementally line-by-line until function body start
   - Validate reconstructed source with `go/format.Source` before `parser.ParseFile`
   - Add error logging (don't fail silently)
   - Unit test complex signatures: `func foo[T any]() (T, error)`

2. **Long-term:** Rewrite to use a proper parser:
   - Integrate with `alecthomas/participle` as recommended in project docs
   - Use the existing Dingo AST from `pkg/ast/` if available
   - Parse the full file context, not reconstructed snippets

---

### IMPORTANT Issues

#### 3. Fragile expression/message extraction
**File:** `pkg/preprocessor/error_prop.go`
**Lines:** ~120-133 (`extractExpressionAndMessage` function)
**Location:** Regex-based parsing of `expr? "message"` syntax

**Issue:**
Regex pattern assumes well-formed input but fails for:
- Complex expressions: `foo(bar?), baz? "msg";` (ignores code after message)
- Nested parentheses or function calls with quotes
- Escaped strings beyond `\"` (e.g., `\n`, `\t` in messages)
- Multiline expressions

```go
// Line ~126
msgPattern := regexp.MustCompile(`^(.*\?)\s*"((?:[^"\\]|\\.)*)"`)
```

**Impact:**
- Incorrect parsing of expressions with errors leads to broken expansions or silent skips
- Causes runtime bugs in transpiled code
- Affects all 8 golden error_prop tests if they include nested calls or complex escapes
- Users will get confusing errors when expressions don't match expected patterns

**Recommendation:**
Replace regex with token-based parsing using `go/scanner`:

```go
func (e *ErrorPropProcessor) extractExpressionAndMessage(line string) (string, string) {
    // Use go/scanner to tokenize
    var s scanner.Scanner
    fset := token.NewFileSet()
    file := fset.AddFile("", fset.Base(), len(line))
    s.Init(file, []byte(line), nil, 0)

    // Parse expression until '?'
    // Extract optional string literal after '?'
    // Validate with ast.ParseExpr
}
```

Add extensive unit tests for edge cases:
- `expr? "msg with \\n escapes"`
- `foo(bar()) + baz()? "error"`
- Nested function calls with quotes

---

#### 4. Overly simplistic import addition
**File:** `pkg/preprocessor/error_prop.go`
**Lines:** ~416-447 (`ensureFmtImport` function)
**Location:** Adding `fmt` import when using error wrapping

**Issue:**
String-based checks risk false positives and corruption:
- `strings.Contains(sourceStr, \"fmt\")` matches `"fmt"` in comments/strings
- Manual string manipulation mangles existing import blocks
- Doesn't handle grouped imports correctly: `import ("fmt"; "other")`
- Adds duplicate blank lines

```go
// Line ~421
if strings.Contains(sourceStr, `import "fmt"`) || strings.Contains(sourceStr, `"fmt"`) {
    return source  // False positive if "fmt" in comment
}
```

**Impact:**
- Could corrupt imports, leading to compilation failures
- Generates unused imports or malformed import blocks
- Violates "Readable Output" design goal (generated Go should look hand-written)
- May break with different import formatting styles

**Recommendation:**
Use `go/ast` to properly modify imports:

```go
func (e *ErrorPropProcessor) ensureFmtImport(source []byte) []byte {
    fset := token.NewFileSet()
    file, err := parser.ParseFile(fset, "", source, parser.ParseComments)
    if err != nil {
        return source // Fallback
    }

    // Check if fmt is already imported
    for _, imp := range file.Imports {
        if imp.Path.Value == `"fmt"` {
            return source
        }
    }

    // Add import using astutil
    astutil.AddImport(fset, file, "fmt")

    // Regenerate source
    var buf bytes.Buffer
    printer.Fprint(&buf, fset, file)
    return buf.Bytes()
}
```

This is more reliable and maintains proper formatting.

---

#### 5. Line-based processing limitation
**File:** `pkg/preprocessor/error_prop.go`
**Lines:** ~42-80 (`Process` function and line splitting)
**Location:** Main processing loop

**Issue:**
Splits input by `\n` and processes per line, assuming code is line-oriented. Doesn't handle multiline expressions:

```dingo
let x =
    longFunctionCall(
        arg1,
        arg2
    )?  // This ? will be missed
```

**Impact:**
- Fails on multiline Dingo code (common in real usage)
- Causes skipped error handling and bugs in generated Go
- Affects tests with long expressions or formatted code
- Users with code formatters will get broken transpilation

**Recommendation:**
Switch to token-based processing:
1. Use a lexer (integrate `participle` as mentioned in `cli-research.md`)
2. Process the entire file as a stream, tracking context across lines
3. Maintain a state machine for multi-line constructs

Short-term workaround: Join lines that end with incomplete expressions (detect unclosed parentheses, commas, etc.)

---

#### 6. Incomplete type regex in type annotation processor
**File:** `pkg/preprocessor/type_annot.go`
**Lines:** ~69-90 (`replaceColonInParams` function)
**Location:** Type pattern matching

**Issue:**
Pattern `(\w+)\s*:\s*(\w+|[\[\]\*\{\}]+[\w\.\[\]\*\{\}]*)` doesn't cover complex types:
- Generics: `T`, `[T any]`
- Interfaces: `io.Reader`
- Qualified imports: `time.Time`, `pkg.Struct`
- Nested types: `map[string][]*pkg.Struct`

```go
// Example failure
func foo(x: map[string]interface{})
// Regex might mangle due to braces in type
```

**Impact:**
- Mangles function signatures with advanced types
- Affects all functions with non-trivial parameters
- Breaks transpilation for modern Go code with interfaces/generics
- Causes parse errors in generated code

**Recommendation:**
Use `go/parser` to fully parse parameters:

```go
func (t *TypeAnnotProcessor) Process(source []byte) ([]byte, []Mapping, error) {
    fset := token.NewFileSet()
    file, err := parser.ParseFile(fset, "", source, 0)
    if err != nil {
        return source, nil, err
    }

    // Visit all function declarations
    ast.Inspect(file, func(n ast.Node) bool {
        if fn, ok := n.(*ast.FuncDecl); ok {
            // Process parameters using AST
            for _, param := range fn.Type.Params.List {
                // Remove colons properly using AST manipulation
            }
        }
        return true
    })

    // Regenerate source
    var buf bytes.Buffer
    printer.Fprint(&buf, fset, file)
    return buf.Bytes(), nil, nil
}
```

Add regex as fallback for simple cases, but handle complex types via AST.

---

### MINOR Issues

#### 7. Limited state management
**File:** `pkg/preprocessor/error_prop.go`
**Lines:** ~14-27 (struct definitions)
**Location:** State tracking in `ErrorPropProcessor`

**Issue:**
- `tryCounter` resets per function but not per expansion scope
- Tracks only one `currentFunc` globally, limiting support for nested functions
- No proper scope stack for complex code structures

**Impact:**
- Limited reuse in large files with many functions
- May cause variable naming conflicts in nested scenarios
- Not a blocker for current use cases but limits scalability

**Recommendation:**
Refactor to use a scope stack:

```go
type scopeStack struct {
    scopes []*funcContext
}

func (s *scopeStack) push(ctx *funcContext) { ... }
func (s *scopeStack) pop() *funcContext { ... }
func (s *scopeStack) current() *funcContext { ... }
```

Make counters and context per-scope. This also improves testability by making state explicit.

---

#### 8. Code duplication in expand functions
**File:** `pkg/preprocessor/error_prop.go`
**Lines:** ~136-243 (`expandAssignment` and `expandReturn`)
**Location:** Expansion logic

**Issue:**
The expansion logic for assignments and returns is nearly identical (~50 lines each), violating DRY (Don't Repeat Yourself) principle. Only difference is the final line:
- Assignment: `var varName = __tmpN`
- Return: `return __tmpN`

**Impact:**
- Maintenance burden (changes must be replicated in both functions)
- Risk of inconsistency between assignment/return handling
- Makes future enhancements harder

**Recommendation:**
Extract common logic into a helper:

```go
func (e *ErrorPropProcessor) expandErrorHandling(
    expr string,
    errMsg string,
    lineNum int,
    finalLine func(tmpVar string) string,
    indent string,
) (string, *Mapping) {
    // Common expansion logic here
    // ...
    buf.WriteString(finalLine(tmpVar))
    return buf.String(), mapping
}

// Usage
func (e *ErrorPropProcessor) expandAssignment(...) {
    return e.expandErrorHandling(expr, errMsg, lineNum,
        func(tmp string) string {
            return fmt.Sprintf("var %s = %s", varName, tmp)
        }, indent)
}
```

---

#### 9. Type annotation processor assumes colon-only in params
**File:** `pkg/preprocessor/type_annot.go`
**Lines:** Entire file (general design)
**Location:** Overall strategy

**Issue:**
Replaces all `:` only within `()`. If Dingo adds colon usage elsewhere in the future (e.g., ternary `:`, struct field tags, map literals), this could break.

**Impact:**
- Future-proofing issue
- Low immediate risk (current Dingo syntax is limited)
- May cause conflicts if ternary operator is added

**Recommendation:**
Add explicit context checks:
- Only replace `:` within function parameter lists
- Skip `:` in conditional expressions (after `?`)
- Document the limitation in code comments

---

#### 10. Simple but potentially brittle keyword replacement
**File:** `pkg/preprocessor/keywords.go`
**Lines:** ~23-26 (`Process` function)
**Location:** `let` to `var` conversion

**Issue:**
`\blet\s+` regex prevents false matches but might replace `let` in strings/comments if quoting is unusual (unlikely but possible).

**Impact:**
- Very low risk in practice
- Trivial to fix if it becomes an issue
- Could cause subtle bugs in edge cases with string literals

**Recommendation:**
For robustness, integrate with AST to replace only in declarations:

```go
// Visit all declarations
ast.Inspect(file, func(n ast.Node) bool {
    if decl, ok := n.(*ast.GenDecl); ok && decl.Tok == token.VAR {
        // This is already a var declaration (from 'let')
    }
    return true
})
```

Alternatively, keep regex but add tests for edge cases (strings containing "let", comments, etc.)

---

## Architecture Review

### Alignment with Plan
The implementation follows the Phase 2.2 plan:
- ✅ Zero value inference via `go/ast` parsing
- ✅ Error message wrapping with `fmt.Errorf`
- ✅ CLI integration with preprocessor pipeline
- ✅ Source map generation
- ⚠️ Expression parsing still uses regex (plan suggested `go/scanner`)

### Design Strengths
1. **Modular processor architecture**: Each feature is a separate processor (type annotations, keywords, error prop)
2. **Source map support**: Proper tracking of transformations for LSP
3. **Progressive enhancement**: Processors run in sequence with clear ordering
4. **Fallback handling**: Silent failures default to safe values (though this hides errors)

### Design Concerns
1. **String-based processing**: Line-by-line splitting limits multiline support
2. **Regex fragility**: Heavy reliance on regex for parsing Go-like syntax
3. **Silent failures**: Many error cases fall back without reporting to user
4. **Limited error recovery**: Parse failures often result in `nil` fallbacks that cause downstream compile errors

---

## Performance Analysis

### Current Performance
- **Regex compilation**: Happens once per `Process()` call (acceptable)
- **String operations**: Multiple splits/joins per file (O(n) where n = file size)
- **AST parsing**: Only for function signatures (minimal overhead)
- **Memory**: Buffers entire file in memory (fine for typical file sizes < 10MB)

### Performance Concerns
- No caching of compiled regexes (minor issue)
- String concatenation in loops could use `strings.Builder`
- Multiple passes over the same content (each processor)

### Recommendations
- Cache compiled regexes as package-level variables
- Use `strings.Builder` consistently instead of `bytes.Buffer` for string operations
- Consider single-pass processing if multiple processors need same data

---

## Testing Recommendations

### Critical Tests Needed
1. **Zero value generation**:
   - Test all built-in types
   - Test custom structs: `func foo() (MyStruct, error)`
   - Test pointers, slices, maps
   - Test generics: `func foo[T any]() (T, error)`

2. **Function signature parsing**:
   - Multiline signatures
   - Generics and type constraints
   - Interface parameters
   - Complex nested types

3. **Expression extraction**:
   - Nested function calls
   - Expressions with escaped strings
   - Multiline expressions
   - Complex operators

4. **Import management**:
   - Files with no imports
   - Files with single import
   - Files with grouped imports
   - Files with `fmt` in comments/strings

### Test Coverage Gaps
Based on the plan, the following should be tested:
- All 8 `error_prop_*.dingo` golden tests (mentioned but not verified)
- Edge cases from `GOLDEN_TEST_GUIDELINES.md`
- Compile tests (ensure generated code compiles)
- Integration tests with full pipeline

---

## Code Quality Summary

### Readability: **Good**
- Clear function names and comments
- Logical structure and flow
- Well-documented intent

### Maintainability: **Fair**
- Code duplication in expand functions
- Heavy regex usage makes changes risky
- Limited error reporting makes debugging hard

### Error Handling: **Needs Improvement**
- Too many silent failures
- Fallbacks hide underlying issues
- Users won't know why transpilation fails

### Go Idioms: **Good**
- Proper use of `bytes.Buffer`
- Good struct design
- Appropriate use of standard library

---

## Recommendations Summary

### Must Fix (Before Merge)
1. Fix zero value generation for custom types (use `typ + "{}"`)
2. Improve function signature parsing (validate before parsing, add error reporting)
3. Replace regex-based expression parsing with token-based approach
4. Fix import management to use `go/ast` properly

### Should Fix (High Priority)
5. Support multiline expressions (token-based processing)
6. Add comprehensive error reporting (don't fail silently)
7. Extract duplicated expansion logic into shared helper

### Nice to Have
8. Add scope stack for nested functions
9. Cache compiled regexes
10. Improve type annotation regex or use AST

### Testing Requirements
- Add unit tests for all critical functions
- Test against all 8 golden error_prop files
- Add fuzzing for expression parsing
- Verify compiled output compiles successfully

---

## Summary

**STATUS:** CHANGES_NEEDED
**CRITICAL_COUNT:** 2
**IMPORTANT_COUNT:** 4
**MINOR_COUNT:** 4

The implementation shows good architectural thinking and follows the plan well, but critical bugs in zero value generation and function parsing will prevent it from working with common Go patterns. The string-based processing approach, while simple, introduces multiline limitations and regex fragility.

**Immediate Action Items:**
1. Fix `getZeroValue` to return `typ + "{}"` for custom types
2. Add validation and error reporting to `parseFunctionSignature`
3. Add unit tests for critical functions
4. Run all 8 golden tests and verify compilation

**Long-term Improvements:**
1. Replace regex parsing with token-based approach (use `go/scanner`)
2. Switch to AST-based import management
3. Add comprehensive test coverage
4. Improve error reporting throughout

The code is not ready for production use but is a solid starting point. With the recommended fixes, it should meet the Phase 2.2 goals.
